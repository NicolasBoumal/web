<title>
    Rayleigh quotient on the sphere: a quick look
</title>

<p>
This is an introductory exercise where we just "go right into it".
We'll use words that are mentioned intuitively in the early lecture (002).
Formal definitions come later.
</p>
<p>
We let $\Rd$ be endowed with its usual Euclidean structure: $\inner{u}{v} = u^\top v$ and $\|u\| = \sqrt{\inner{u}{u}}$.
Let
\begin{aligned}
    \Sd = \{ x \in \Rd : \|x\| = 1 \}
\end{aligned}
be the unit sphere in $\reals^d$.
You can take for granted that the sphere is an embedded submanifold of $\Rd$: we'll formalize that soon.
Later, we will see that we can even turn it into a Riemannian manifold by using the Euclidean structure of $\Rd$; and that in turn this provides us with a notion of gradient for functions on $\Sd$.
Our first aim is to work our way up to a first bit of code to address the following problem.
</p>
<p>
Let $A \in \reals^{d \times d}$ be a symmetric matrix.
We want to solve
\begin{aligned}
    \min_{x \in \Sd} f(x), && \textrm{ with} && f(x) = \inner{x}{Ax}.
\end{aligned}
Notice that $f$ coincides with the <a href="https://en.wikipedia.org/wiki/Rayleigh_quotient" target="_blank">Rayleigh quotient</a> $\frac{\inner{x}{A x}}{\inner{x}{x}}$ when restricted to the sphere.
</p>

<question>
    Show that the minimal value of $f$ on $\Sd$ is the smallest eigenvalue of $A$.
</question>
<sketch>
    Since $A$ is symmetric, it admits an orthonormal eigenbasis.
</sketch>
<answer>
    Let $\{u_1,\ldots,u_d\}$ be an orthonormal eigenbasis of $A$. Then writing $x = \sum_{i=1}^d \mu_i u_i$ it holds that
    \begin{aligned}
        f(x) = \left ( \sum_{i=1}^d \mu_i u_i^\top \right ) \left ( \sum_{i=1}^d \mu_i A u_i \right ) = \sum_{i=1}^d \lambda_i \mu_i^2 \geq \lambda_{\min} \sum_{i=1}^d \mu_i^2 = \lambda_{\min}
    \end{aligned}
    as $\sum_{i=1}^d \mu_i^2 = ||x||_2^2 = 1$ and where  $\lambda_{\min} = \min_{i=1,\ldots, d} \lambda_i$.
</answer>

<question>
    What is the tangent space $\T_x \Sd$ at $x \in \mathbb{S}^{d-1}$?
</question>
<sketch>
    Recall our early intuition that to linearize a set defined by $h(x) = 0$, it helps to linearize $h$.
</sketch>
<answer>
    A point $x$ is on the sphere exactly if $h(x) = 0$, where $h(x)=  x^\top x - 1$.
    Pick such a point $x$.
    If we move away from $x$ a bit, say, to $x + v$, then
    \begin{aligned}
        h(x + v) = h(x) + \D h(x)[v] + O(\|v\|^2).
    \end{aligned}
    Since $h(x) = 0$, the right-hand side is almost zero if $\D h(x)[v] = 0$.
    In other words, $x + v$ almost satisfies the equation $h(x + v) = 0$ when $v$ is in the kernel of $\D h(x)$.
    Thus, it makes good intuitive sense that $\ker\D h(x)$ might provide a reasonable linearization of the sphere around $x$.
    We can compute:
    \begin{aligned}
        \D h(x)[v] = \lim_{t \to 0} \frac{h(x+tv) - h(x)}{t} = \lim_{t \to 0} \frac{(x+tv)^\top (x+tv) - 1 - x^\top x + 1}{t} = 2 x^\top v.
    \end{aligned}
    As a result,
    \begin{aligned}
        \T_x \Sd = \ker \D h(x) = \{ v : x^\top v = 0 \} = \text{span}(x)^{\perp} = \{x \in \reals^d \; | \; \langle x,v \rangle = 0\}.
    \end{aligned}
    Indeed, soon in the course, we provide formal definitions that indicate that this is "the right way" to linearize the sphere.
</answer>

<p>
Let $\calM$ be an embedded submanifold of $\Rd$ with its Euclidean inner product $\inner{\cdot}{\cdot}$ (in our case $\calM = \Sd$).
The inner product $\inner{\cdot}{\cdot}$ is defined for all of $\Rd$.
Since $\T_x \calM$ is a subspace of $\Rd$, we can restrict $\inner{\cdot}{\cdot}$ to $\T_x \calM$ to get an inner product on $\T_x \calM$.
Doing so, we endow all tangent spaces of $\calM$ with an inner product, in such a way that inner products at nearby points are similar: that is what we call a Riemannian metric on $\calM$, turning it into a Riemannian manifold.
</p>
<p>
From there, we will define the Riemannian gradient of $f$ (denoted by $\grad f$), and we will prove the following: if $\bar f \colon \Rd \to \reals$ is a smooth function such that $\bar f|_{\calM} = f$, then $\grad f(x)$ is the orthogonal projection of $\grad \bar f(x)$ to $\T_x \calM$.
This is useful, because $\bar f$ is just a function in a Euclidean space: we already know how to compute gradients for that kind of function.
</p>

<question>
    Give a formula for orthogonal projection from $\Rd$ onto $\T_x \mathbb{S}^{d-1}$, denoted $\Proj_x$.
</question>
<sketch>
    Recall the definition of an orthogonal projector and how to get the orthogonal projector for a linear space $E^\perp \subseteq \reals^d$ knowing the orthogonal projector for $E\subseteq \reals^d$.
</sketch>
<answer>
    Following the hint and using that for $x \in \Sd$ the tangent space is given by $\T_x \mathbb{S}^{d-1} = \text{span}(x)^\perp$ we get that the orthogonal projector is given by
    \begin{aligned}
        \Proj_x(v) = v - x (x^\top v) = (I - x x^\top) v.
    \end{aligned}
</answer>

<question>
    Give a formula for $\grad f(x)$.
</question>
<sketch>
    Determine the euclidean gradient of an extension of $f$ and then use that the Riemannian gradient is the projection of the euclidean gradient of the extension onto the tangent space in the case of a Riemannian submanifold.
</sketch>
<answer>
    Observe that $\overline{f}(x) = x^\top A x$ (defined on all of $\reals^d$) is smooth and it coincides with $f$ on the sphere; thus, it is a smooth extension of $f$.
    The euclidean gradient of this extension is $\grad \overline{f}(x) = 2 Ax$.
    Thus the Riemannian gradient is
    \begin{aligned}
        \grad f(x) = (I - x x^\top) \grad \overline{f}(x) = 2 (I - x x^\top) A x.
    \end{aligned}
</answer>
<p>
    The critical points of $f$ are the points $x$ on the sphere such that $\grad f(x) = 0$.
</p>
<question>
    Can you relate the critical points of $f$ to eigenvectors of $A$?
</question>
<sketch>
    A nonzero vector $v$ is an eigenvector of $A$ if and only if $Av = \lambda v$ for some scalar $\lambda$.
</sketch>
<answer>
    A point $x \in \mathbb{S}^{d-1}$ is critical if and only if
    \begin{aligned}
        0 = \frac{1}{2}\grad f(x) = (I - x x^\top) A x = Ax - (x^\top A x) x.
    \end{aligned}
    Thus, each critical point of $f$ is an eigenvector of $A$ with eigenvalue $\lambda = x^\top A x$.
    The other way around, if $x$ is a unit-norm eigenvector of $A$, then it is a critical point of $f$; do you see why?
</answer>

<p>
A retraction on a manifold $\calM$ (in our case the sphere $\calM = \Sd$) is a smooth map $\Retr$ which takes as input a point $x \in \calM$ and a tangent vector $v \in \T_x\calM$ and outputs a point $\Retr_x(v) \in \calM$. We will see later how to define smoothness for such a map.
It should have the property that $c(t) = \Retr_x(tv)$ is a smooth curve that satisfies $c(0) = x$ and $c'(0) = v$.
</p>

<question>
    Propose a retraction for the sphere (there are many possible choices).
</question>
<sketch>
    Think of the closest point on the sphere to $x+v$.
</sketch>
<answer>
    Given a nonzero point $z \neq 0$ in $\reals^d$, the closest point to $z$ on the sphere is $z/\|z\|$ (do you see why?).
    This suggests that we use the following as a retraction, for all $x$ on the sphere and $v$ in the tangent space to the sphere at $x$:
    \begin{aligned}
        \Retr_x(v) = \frac{x + v}{\|x + v\|}.
    \end{aligned}
    Since $x^\top v = 0$ (because $v$ is tangent at $x$), we have $\|x + v\|^2 = (x+v)^\top (x+v) = x^\top x + v^\top v = 1 + \|v\|^2$.
    Then, each curve $c(t) = \Retr_x(tv) = \frac{x + tv}{\sqrt{1 + t^2 \|v\|^2}}$ clearly has the properties $c(0) = x$ and $c'(0) = v$ (the latter requires a small computation).
</answer>

<question>
    Write down the Riemannian gradient descent (RGD) iteration for $f$ on $\mathbb{S}^{d-1}$ using your retraction.
    Think about how you might choose step sizes for RGD: keep it simple for now, we're just getting started.
</question>
<sketch>
    It's ok to pick a constant step size and to tune it manually later in your code -- we'll do better soon.
</sketch>
<answer>
    Given $x_0$ on the sphere, Riemannian gradient descent generates $x_1, x_2, x_3, \ldots$ on the sphere by iteration:
    \begin{aligned}
        x_{k+1} = \Retr_{x_k}(-\eta_k \grad f(x_k)),
    \end{aligned}
    where $\eta_k > 0$ is a positive step size.
    For example, one might set $\eta_k = \eta \triangleq 1 / (2 \|A\|_F)$, where $\|A\|_F = \sqrt{\sum_{i,j} A_{ij}^2}$ is the Frobenius norm of $A$.
    That's likely to be very slow, but it will do for now.
</answer>

<question>
Write code to try out your algorithm.
</question>

<answer>
    We have the following code.
    <matlab href="RGDsphere02.m"> </matlab>
</answer>

<question>
    As a nice touch, you can visualize the problem and what your algorithm is doing in small dimensions. Let $d=3$, and let $A$ be a symmetric matrix of your choosing. Visualize $f$ on the sphere as a colormap. Use this plot to identify local minima/maxima and saddle points of $f$. Can you visualize the iterates of your algorithm on that sphere ? How does the plot change as you vary $A$ (think about special cases when $A$ has eigenvalues with geometric multiplicities larger than one) ?
</question>

<answer>
    We have the following code.
    <matlab href="mainsphere02.m"> </matlab>
</answer>
